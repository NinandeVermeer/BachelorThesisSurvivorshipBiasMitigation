{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the effect of survivorship bias mitigation on the performance of a recidivism prediction tool \n",
    "\n",
    "This code is part of the bachelor thesis *Exploring the effect of survivorship bias mitigation on the performance of a recidivism prediction tool* of Ninande Vermeer (student number 11269057) of the University of Amsterdam, in cooperation with KPMG.\n",
    "\n",
    "The code is inspired on the findings of Wilson Pok (https://www.ambiata.com/blog/2019-12-13-bias-detection-and-mitigation/ (Wilson Pok, 13 Dec 2019, Ambiata)).\n",
    "\n",
    "## Document setup\n",
    "\n",
    "Download or clone the AI Fairness 360 toolkit of IBM on Github: https://github.com/IBM/AIF360. Position this prototype file within the aif360(-master) folder.\n",
    "\n",
    "Make sure that pandas, numpy, matplotlib and sklearn are accessible and import all necessary packages. \n",
    "\n",
    "### Import necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.explainers import MetricTextExplainer, MetricJSONExplainer\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Functions overview\n",
    "\n",
    "This chapter contains all functions. It is divided in several sections explained below.\n",
    "\n",
    "1. *Synthetic dataset* contains all functions about generating and merging datasets.\n",
    "2. *Convert synthetic dataset to AIF360 format*  contains a function to convert a onehot encoded dataframe into a BinaryLabelDataset object of the AI Fairness 360 toolkit.\n",
    "3. *Machine learning* consists of 3 subsections that consists of 1) aid functions, 2) a function to perform one machine learning loop and 3) functions to do multiple machine learning loops to obtain a mean result.\n",
    "4. *Visualisation* contains all functions involved in visualising the dataset and results.\n",
    "5. *Conditional probabilities* contains the functions to calculate probabilities.\n",
    "\n",
    "All functions have a small documentation paragraph that explaines its input and the output details.\n",
    "\n",
    "### 1.1. Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CREATE DATASET\n",
    "Input:  n_people (amount of people in dataset), \n",
    "        p_male (percentage of men in dataset),\n",
    "        risk_male (percentage of men classified as high risk),\n",
    "        risk_female (percentage of women classified as high risk)\n",
    "Output: df, df_onehot (dataframe and the onehot encoded dataframe)\n",
    "'''\n",
    "def synthesize_data(n_people, p_male, risk_male, risk_female):\n",
    "    p_female = 1 - p_male\n",
    "\n",
    "    # Creating list with gender according to ratio\n",
    "    gender = np.random.choice(['male', 'female'], size=n_people, p=[p_male, p_female])\n",
    "\n",
    "    # Creating a dataframe using the list with genders\n",
    "    df = pd.DataFrame({'gender' : gender})\n",
    "\n",
    "    # Giving each individual a risk rate (1 = high, 0 = low) according to the high risk ratio\n",
    "    df.loc[df.gender == 'male', 'risk'] = np.random.choice([1, 0], size=len(df.loc[df.gender == 'male']), p=[risk_male , 1 - risk_male])\n",
    "    df.loc[df.gender == 'female', 'risk'] = np.random.choice([1, 0], size=len(df.loc[df.gender == 'female']), p=[risk_female, 1 - risk_female])\n",
    "\n",
    "    df['risk'] = df['risk'].astype(int)\n",
    "    \n",
    "    # Encode to make gender readable for AIF360\n",
    "    df_onehot = pd.concat([df[['risk']], pd.get_dummies(df[['gender']])], axis=1)\n",
    "    \n",
    "    return df, df_onehot\n",
    "\n",
    "''' CREATE DATASET WITH NOISE\n",
    "--> Adds the attributes 'age', 'educational level', 'crime rate' and 'family history' to the dataset\n",
    "Input:  n_people (amount of people in dataset), \n",
    "        p_male (percentage of men in dataset),\n",
    "        risk_male (percentage of men classified as high risk),\n",
    "        risk_female (percentage of women classified as high risk)\n",
    "Output: df, df_onehot (dataframe and the onehot encoded dataframe)\n",
    "'''\n",
    "def synthesize_data_with_noise(n_people, p_male, risk_male, risk_female):\n",
    "    p_female = 1 - p_male\n",
    "\n",
    "    # Creating list with gender according to ratio\n",
    "    gender = np.random.choice(['male', 'female'], size=n_people, p=[p_male, p_female])\n",
    "\n",
    "    # Creating a dataframe using the list with genders\n",
    "    df = pd.DataFrame({'gender' : gender})\n",
    "\n",
    "    # Giving each individual a risk rate (1 = high, 0 = low) according to the high risk ratio\n",
    "    df.loc[df.gender == 'male', 'risk'] = np.random.choice([1, 0], size=len(df.loc[df.gender == 'male']), p=[risk_male , 1 - risk_male])\n",
    "    df.loc[df.gender == 'female', 'risk'] = np.random.choice([1, 0], size=len(df.loc[df.gender == 'female']), p=[risk_female, 1 - risk_female])\n",
    "\n",
    "    df['risk'] = df['risk'].astype(int)\n",
    "    \n",
    "    # Giving each individual an age\n",
    "    mu, sigma = 45, 8\n",
    "    \n",
    "    df.loc[df.risk == 1, 'age'] = np.floor(np.random.normal(mu, sigma, len(df.loc[df.risk == 1])))\n",
    "    df.loc[df.risk == 0, 'age'] = np.floor(np.random.normal(mu, sigma, len(df.loc[df.risk == 0])))\n",
    "    \n",
    "    df['age'] = df['age'].astype(int)\n",
    "    \n",
    "    # Giving each individual an educational level\n",
    "    edu_levels = ['A', 'B', 'C', \"D\"]\n",
    "    edu_chance = [0.25, 0.25, 0.25, 0.25]\n",
    "    \n",
    "    df.loc[df.gender == 'male', 'education'] = np.random.choice(edu_levels, size=len(df.loc[df.gender == 'male']), p=edu_chance)\n",
    "    df.loc[df.gender == 'female', 'education'] = np.random.choice(edu_levels, size=len(df.loc[df.gender == 'female']), p=edu_chance)\n",
    "    \n",
    "    # Assigning a criminal degree to their crimes\n",
    "    crime_rate = [1, 2, 3, 4]\n",
    "    crime_chance = [0.25, 0.25, 0.25, 0.25]\n",
    "    \n",
    "    df.loc[df.gender == 'male', 'crime rate'] = np.random.choice(crime_rate, size=len(df.loc[df.gender == 'male']), p=crime_chance)\n",
    "    df.loc[df.gender == 'female', 'crime rate'] = np.random.choice(crime_rate, size=len(df.loc[df.gender == 'female']), p=crime_chance)\n",
    "    \n",
    "    df['crime rate'] = df['crime rate'].astype(int)\n",
    "    \n",
    "    # Do their family have a criminal history\n",
    "    df.loc[df.gender == 'male', 'family history'] = np.random.choice([0, 1], size=len(df.loc[df.gender == 'male']), p=[0.5, 0.5])\n",
    "    df.loc[df.gender == 'female', 'family history'] = np.random.choice([0, 1], size=len(df.loc[df.gender == 'female']), p=[0.5, 0.5])\n",
    "    \n",
    "    df['family history'] = df['family history'].astype(int)   \n",
    "    \n",
    "    # Encode to make gender readable for AIF360\n",
    "    df_onehot = pd.concat([df[['risk']], df[['age']], df[['crime rate']], df[['family history']], pd.get_dummies(df[['gender', 'education']])], axis=1)\n",
    "    \n",
    "    return df, df_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' SUBSET REALITY (substracts the new individuals from reality) \n",
    "Input:  df_reality (onehot encoded reality dataset),\n",
    "        predicted_labels (predicted risk labels by trained model),\n",
    "        fracs (tuple containing the percentage to substract of each group: \n",
    "        1. men with low risk, \n",
    "        2. men with high risk, \n",
    "        3. women with low risk, \n",
    "        4. women with high risk)\n",
    "Output: df_new (the new entities in an onehot encoded dataset)\n",
    "'''\n",
    "def subset_reality(df_reality, predicted_labels, fracs):\n",
    "    frac_m_0, frac_m_1, frac_f_0, frac_f_1 = fracs\n",
    "    \n",
    "    # Add predicted labels to reality Dataframe\n",
    "    df_reality['predicted_label'] = predicted_labels.tolist()\n",
    "    df_reality['predicted_label'] = df_reality['predicted_label'].astype(int)\n",
    "    \n",
    "    # Divide reality Dataframe into separate male and female datasets\n",
    "    df_male = df_reality[df_reality.gender_female == 0]\n",
    "    df_female = df_reality[df_reality.gender_female == 1]\n",
    "    \n",
    "    # Divide male and female datasets into separate high and low risk subsets\n",
    "    df_male_0 = df_male[df_male.predicted_label == 0]\n",
    "    df_male_1 = df_male[df_male.predicted_label == 1]\n",
    "    df_female_0 = df_female[df_female.predicted_label == 0]\n",
    "    df_female_1 = df_female[df_female.predicted_label == 1]\n",
    "\n",
    "    # Take samples from the 4 subsets (and prevent sampling from empty list)\n",
    "    subsets = []\n",
    "    if df_male_0.empty != True: \n",
    "        df_m_0 = df_male_0.sample(frac=frac_m_0, random_state=1)\n",
    "        subsets.append(df_m_0)\n",
    "    if df_male_1.empty != True: \n",
    "        df_m_1 = df_male_1.sample(frac=frac_m_1, random_state=1)\n",
    "        subsets.append(df_m_1)  \n",
    "    if df_female_0.empty != True: \n",
    "        df_f_0 = df_female_0.sample(frac=frac_f_0, random_state=1)\n",
    "        subsets.append(df_f_0)  \n",
    "    if df_female_1.empty != True: \n",
    "        df_f_1 = df_female_1.sample(frac=frac_f_1, random_state=1)\n",
    "        subsets.append(df_f_1)\n",
    "    \n",
    "    # Merge all samples together\n",
    "    df_merge = pd.concat(subsets)\n",
    "    \n",
    "    # Reset index\n",
    "    new = df_merge.reset_index(drop=True)\n",
    "    \n",
    "    # Drop predicted labels\n",
    "    df_new = new.drop(['predicted_label'], axis=1)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Convert synthetic dataset to AIF360 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CONVERTING ONEHOT ENCODED DATAFRAME TO AIF360 DATASET OBJECT\n",
    "Input:  df_onehot (onehot encoded dataframe)\n",
    "Output: df_aif (BinaryLabelDataset object),\n",
    "        privileged_group (men)\n",
    "        unprivileged_group (women)\n",
    "'''\n",
    "def convert_aif360(df_onehot):\n",
    "    # Convert the dataset to a BinaryLabelDataset\n",
    "    df_aif = BinaryLabelDataset(df=df_onehot.drop('gender_female', axis=1), label_names=['risk'], protected_attribute_names=['gender_male'])\n",
    "\n",
    "    # Define privileged (females) and unprivileged (males) group\n",
    "    priv_group = [{'gender_male': 0}] \n",
    "    unpriv_group = [{'gender_male': 1}] \n",
    "    \n",
    "    return df_aif, priv_group, unpriv_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Machine Learning\n",
    "\n",
    "#### 1.3.1. Aid functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "''' TRAIN LINEAR REGRESSION MODEL\n",
    "Input:  dataset (BinaryLabelDataset object)\n",
    "Output: model (trained model),\n",
    "        scale (scale of the model)\n",
    "'''\n",
    "def train_linear_regression(dataset):\n",
    "    scale = StandardScaler().fit(dataset.features)\n",
    "    model = LogisticRegression(random_state=0, solver='liblinear')\n",
    "    x_train = scale.transform(dataset.features)\n",
    "    y_train = dataset.labels.ravel()\n",
    "    model.fit(x_train, y_train, sample_weight=dataset.instance_weights)\n",
    "    return model, scale\n",
    "\n",
    "# VALIDATION\n",
    "''' RETURN PROBABILITIES OF THE PREDICTED RISK\n",
    "Input:  dataset (BinaryLabelDataset object),\n",
    "        model (trained linear regression model),\n",
    "        scale (scale of the trained model)\n",
    "Output: label_prob (the probability of the predicted risk \n",
    "        (for a predicted risk of 0 and 1 respectively))\n",
    "'''\n",
    "def pred_prob_label(dataset, model, scale):\n",
    "    x_test = scale.transform(dataset.features)\n",
    "    label_prob = model.predict_proba(x_test)\n",
    "    return label_prob\n",
    "\n",
    "''' GET BEST THRESHOLD \n",
    "Input:  dataset (BinaryLabelDataset object),\n",
    "        label_probs (the probabilities of the predicted risk values),\n",
    "        thresholds (probable thresholds),\n",
    "        priv (privileged group),\n",
    "        unpriv (unprivileged group)\n",
    "Output: best_accuracy (highest obtained accuracy score),\n",
    "        best_threshold (threshold corresponding to the highest accuracy)\n",
    "'''\n",
    "def get_best_thresh(dataset, label_probs, thresholds, priv, unpriv):\n",
    "    accuracies = []\n",
    "\n",
    "    # Calculate accuracy for each threshold value\n",
    "    for thresh in thresholds:\n",
    "        y_validate_pred = (label_probs[:,1] > thresh).astype(np.double)\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = y_validate_pred\n",
    "\n",
    "        metric = ClassificationMetric(dataset, dataset_pred, unpriv, priv)\n",
    "        acc = metric.accuracy()\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    # Find threshold for best accuracy\n",
    "    threshold_best_index = np.where(accuracies == np.max(accuracies))[0][0]\n",
    "    best_threshold = np.array(thresholds)[threshold_best_index]\n",
    "\n",
    "    # Find accuracy at this threshold\n",
    "    best_accuracy = accuracies[threshold_best_index]\n",
    "\n",
    "    return best_accuracy, best_threshold\n",
    "\n",
    "''' VALIDATE MODEL\n",
    "Input:  dataset (BinaryLabelDataset object),\n",
    "        lr_model (trained linear regression model),\n",
    "        lr_scale (scale of the trained model)\n",
    "        priv (privileged group),\n",
    "        unpriv (unprivileged group)\n",
    "Output: best_acc (best obtained accuracy),\n",
    "        best_thres (threshold used for the best accuracy score)\n",
    "'''\n",
    "def validate(dataset, lr_model, lr_scale, priv, unpriv):\n",
    "    thresholds = np.linspace(0.01, 0.5, 100)\n",
    "    label_probs = pred_prob_label(dataset, lr_model, lr_scale)\n",
    "    best_acc, best_thres = get_best_thresh(dataset, label_probs, thresholds, priv, unpriv)   \n",
    "    return best_acc, best_thres\n",
    "\n",
    "# TESTING\n",
    "''' TEST MODEL\n",
    "Input:  dataset (BinaryLabelDataset object),\n",
    "        lr_model (trained linear regression model),\n",
    "        lr_scale (scale of model),\n",
    "        best_thres (threshold used for the best accuracy score),\n",
    "        priv (privileged group),\n",
    "        unpriv (unprivileged group)\n",
    "Output: class_metric (ClassificationMetric),\n",
    "        dataset_pred (predicted dataset)\n",
    "'''\n",
    "def test(dataset, lr_model, lr_scale, best_thres, priv, unpriv):\n",
    "    # Get label probabilities\n",
    "    label_probs = pred_prob_label(dataset, lr_model, lr_scale)\n",
    "    \n",
    "    # Use best threshold to test model\n",
    "    y_pred = (label_probs[:,1] > best_thres).astype(np.double)\n",
    "    dataset_pred = dataset.copy()\n",
    "    dataset_pred.labels = y_pred\n",
    "    \n",
    "    # Get ClassificationMetric\n",
    "    class_metric = ClassificationMetric(dataset, dataset_pred, unpriv, priv)\n",
    "    \n",
    "    return class_metric, dataset_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2. One loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' MACHINE LEARNING\n",
    "Input:  df_aif (BinaryLabelDataset object),\n",
    "        trn_val_tst_ratio (ratio for training, validation and test set),\n",
    "        priv (privileged group),\n",
    "        unpriv (unprivileged group),\n",
    "        reweigh ('yes' means using the reweighing algorithm)\n",
    "Output: lr_model (trained model), \n",
    "        lr_scale (scale of trained model), \n",
    "        best_thres (threshold used to obtain the highest accuracy score in validation), \n",
    "        class_metric_tst (ClassificationMetric of the test set),\n",
    "        result_round (List with the real and predicted amounts for the\n",
    "        1. total low risk labeled individuals, \n",
    "        2. low risk labeled women, \n",
    "        3. low risk labeled men,\n",
    "        4. total high risk labeled individuals,\n",
    "        5. high risk labeled women,\n",
    "        6. high risk labeled men)\n",
    "'''\n",
    "def learning_loop(df_aif, trn_val_tst_ratio, priv, unpriv, reweigh='no'):\n",
    "    df_trn, df_val, df_tst = df_aif.split(trn_val_tst_ratio, shuffle=True)\n",
    "    \n",
    "    # Training with reweighing\n",
    "    if reweigh == 'yes':\n",
    "        # Create reweighing obejct\n",
    "        RW = Reweighing(unprivileged_groups=unpriv, privileged_groups=priv)\n",
    "\n",
    "        # Reweigh the training dataset\n",
    "        RW.fit(df_trn) \n",
    "        df_transf_trn = RW.transform(df_trn)\n",
    "\n",
    "        # First fairness metrics\n",
    "        metric_trn = BinaryLabelDatasetMetric(df_transf_trn, unpriv, priv)\n",
    "        \n",
    "        # Training the model\n",
    "        lr_model, lr_scale = train_linear_regression(df_transf_trn)\n",
    "\n",
    "    # Training without reweighing\n",
    "    else:\n",
    "        # TRAINING\n",
    "        # First fairness metrics\n",
    "        metric_trn = BinaryLabelDatasetMetric(df_trn, unpriv, priv)\n",
    "\n",
    "        # Training the model\n",
    "        lr_model, lr_scale = train_linear_regression(df_trn)\n",
    "\n",
    "    # VALIDATION\n",
    "    best_acc, best_thres = validate(df_val, lr_model, lr_scale, priv, unpriv)\n",
    "    \n",
    "    #print(\"best threshold\", best_thres)\n",
    "    #best_thres = 0.5\n",
    "\n",
    "    # TESTING\n",
    "    class_metric_tst, dataset_pred = test(df_tst, lr_model, lr_scale, best_thres, priv, unpriv)\n",
    "    \n",
    "    bin_metrics = BinaryLabelDatasetMetric(df_tst, unpriv, priv)\n",
    "    bin_metrics_pred = BinaryLabelDatasetMetric(dataset_pred, unpriv, priv)\n",
    "    \n",
    "    # Collecting real amount of high and low risk labels\n",
    "    low_risk_all = bin_metrics.num_negatives()\n",
    "    low_risk_priv = bin_metrics.num_negatives(privileged=True)\n",
    "    low_risk_unpriv = bin_metrics.num_negatives(privileged=False)\n",
    "    high_risk_all = bin_metrics.num_positives()\n",
    "    high_risk_priv = bin_metrics.num_positives(privileged=True)\n",
    "    high_risk_unpriv = bin_metrics.num_positives(privileged=False)\n",
    "    \n",
    "    # Collecting prediction amount of high and low risk labels\n",
    "    low_risk_all_pred = bin_metrics_pred.num_negatives()\n",
    "    low_risk_priv_pred = bin_metrics_pred.num_negatives(privileged=True)\n",
    "    low_risk_unpriv_pred = bin_metrics_pred.num_negatives(privileged=False)\n",
    "    high_risk_all_pred = bin_metrics_pred.num_positives()\n",
    "    high_risk_priv_pred = bin_metrics_pred.num_positives(privileged=True)\n",
    "    high_risk_unpriv_pred = bin_metrics_pred.num_positives(privileged=False)\n",
    "    \n",
    "    # Combine real and predicted amounts\n",
    "    result_low_all = [low_risk_all, low_risk_all_pred]\n",
    "    result_low_priv = [low_risk_priv, low_risk_priv_pred]\n",
    "    result_low_unpriv = [low_risk_unpriv, low_risk_unpriv_pred]\n",
    "    result_high_all = [high_risk_all, high_risk_all_pred]\n",
    "    result_high_priv = [high_risk_priv, high_risk_priv_pred]\n",
    "    result_high_unpriv = [high_risk_unpriv, high_risk_unpriv_pred]\n",
    "    \n",
    "    result_round = [result_low_all, result_low_priv, result_low_unpriv, result_high_all, result_high_priv, result_high_unpriv]\n",
    "\n",
    "    return lr_model, lr_scale, best_thres, class_metric_tst, result_round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3. Multiple loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PROCESS SIMULATION\n",
    "Input:  N (amount of loops),\n",
    "        df_onehot (onehot encoded dataframe),\n",
    "        trn_val_tst_ratio (ratio for training, validation and test set),\n",
    "        data_settings (tuple: n_people, p_male, risk_male, risk_female, fracs),\n",
    "        reweigh ('yes' means using the reweighing algorithm),\n",
    "        noise ('yes' means adding noise while generating the dataset)\n",
    "Output: ACC (list of accuracies of test set)\n",
    "        amounts (the percentage high/low risk labeled men/women in the dataset)\n",
    "        results (list with real and predicted numbers of high and low risk labeled individuals)\n",
    "        thresholds (list of the best thresholds)\n",
    "'''\n",
    "def multiple_learning(N, df_onehot, trn_val_tst_ratio, data_settings, reweigh='no', noise='yes'):\n",
    "    i = 0\n",
    "    \n",
    "    n_people, p_male, risk_male, risk_female, fracs = data_settings\n",
    "    \n",
    "    ACC = []\n",
    "    female_1 = []\n",
    "    female_0 = []\n",
    "    male_1 = []\n",
    "    male_0 = []\n",
    "    results = []\n",
    "    thresholds = []\n",
    "    \n",
    "    while i < N:\n",
    "        i += 1\n",
    "        \n",
    "        pivot_table = df_onehot.pivot_table(index='risk', columns='gender_male', aggfunc='size')\n",
    "        total = pivot_table[0][1] + pivot_table[0][0] + pivot_table[1][1] + pivot_table[1][0]\n",
    "        female_1.append((pivot_table[0][1]/total)*100)\n",
    "        female_0.append((pivot_table[0][0]/total)*100)\n",
    "        male_1.append((pivot_table[1][1]/total)*100)\n",
    "        male_0.append((pivot_table[1][0]/total)*100)\n",
    "        \n",
    "        # Get trained model with the current dataset (df_onehot)\n",
    "        df_aif, priv, unpriv = convert_aif360(df_onehot)\n",
    "        metric_aif = BinaryLabelDatasetMetric(df_aif, unpriv, priv)\n",
    "        lr_model, lr_scale, best_thres, class_metric_tst, result_round = learning_loop(df_aif, trn_val_tst_ratio, priv, unpriv, reweigh)\n",
    "        \n",
    "        # Append the results for current round to the list of results\n",
    "        results.append(result_round)\n",
    "        \n",
    "        # Append the best threshold for each round to the thresholds list\n",
    "        thresholds.append(best_thres)\n",
    "        \n",
    "        # Add new individuals to the dataset for the next round\n",
    "        ## Create reality dataset\n",
    "        if noise == 'yes':\n",
    "            _, df_reality = synthesize_data_with_noise(n_people, p_male, risk_male, risk_female)\n",
    "        else:\n",
    "            _, df_reality = synthesize_data(n_people, p_male, risk_male, risk_female)\n",
    "            \n",
    "        df_reality_aif360, _, _ = convert_aif360(df_reality)\n",
    "        \n",
    "        ## Use trained model to predict the risk\n",
    "        _, dataset_pred = test(df_reality_aif360, lr_model, lr_scale, best_thres, priv, unpriv)\n",
    "        \n",
    "        ## Get subset (arrested individuals) of reality\n",
    "        df_new = subset_reality(df_reality, dataset_pred.labels, fracs)\n",
    "        \n",
    "        ## Merge subset with the dataset\n",
    "        df_onehot = df_onehot.append(df_new)\n",
    "        df_onehot = df_onehot.reset_index(drop=True)\n",
    "            \n",
    "        ACC.append(class_metric_tst.accuracy().round(3))\n",
    "        \n",
    "    amounts = [female_1, male_1, female_0, male_0]\n",
    "    \n",
    "    return ACC, amounts, results, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PROCESS SIMULATION MEAN\n",
    "Input:  M (amount of simulations)\n",
    "        N (amount of loops),\n",
    "        df_general (onehot encoded dataframe),\n",
    "        trn_val_tst_ratio (ratio for training, validation and test set),\n",
    "        data_settings (tuple: n_people, p_male, risk_male, risk_female, fracs),\n",
    "        reweigh ('yes' means using the reweighing algorithm),\n",
    "        noise ('yes' means adding noise while generating the dataset)\n",
    "Output: ACC_mean (accuracy of test set)\n",
    "        amounts_mean (mean of percentages of high/low risk labeled men/women)\n",
    "        np.round(results_mean,0) (mean of amounts of total high/low risk labeled individuals/men/women, 0 decimals)\n",
    "        np.round(thresholds_mean,3) (mean of the best thresholds, 3 decimales)\n",
    "'''\n",
    "def multiple_learning_mean(M, N, df_general, trn_val_tst_ratio, data_settings, reweigh='no', noise='yes'):\n",
    "    i = 0 \n",
    "    \n",
    "    ACC_all = []\n",
    "    amounts_all = []\n",
    "    results_all = []\n",
    "    thresholds_all = []\n",
    "    \n",
    "    if reweigh == 'no':\n",
    "        print(\"Machine learning without reweighing\")\n",
    "    else:\n",
    "        print(\"Machine learning with reweighing\")\n",
    "    \n",
    "    while i < M:\n",
    "        i += 1\n",
    "        print(\"round\", i)\n",
    "        ACC, amounts, results, thresholds = multiple_learning(N, df_general, trn_val_tst_ratio, data_settings, reweigh, noise)\n",
    "        ACC_all.append(ACC)\n",
    "        amounts_all.append(amounts)\n",
    "        results_all.append(results)\n",
    "        thresholds_all.append(thresholds)\n",
    "    \n",
    "    ACC_mean = np.mean(ACC_all, axis=0)\n",
    "    amounts_mean = np.mean(amounts_all, axis=0)\n",
    "    results_mean = np.mean(results_all, axis=0)\n",
    "    thresholds_mean = np.mean(thresholds_all, axis=0)\n",
    "    \n",
    "    return ACC_mean, amounts_mean, np.round(results_mean,0), np.round(thresholds_mean,3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ATTACH LABEL TO BAR(S) IN BARPLOT DISPLAYING ITS HEIGHT VALUE\n",
    "input:  ax (barplot),\n",
    "        brs (one or several bars)\n",
    "output: text labels on bars on the ax barplot\n",
    "'''\n",
    "def bar_label(ax, brs, dec='.3f'):\n",
    "    for br in brs:\n",
    "        height = br.get_height()\n",
    "        ax.annotate(format(height, dec),\n",
    "                    xy=(br.get_x() + br.get_width()/2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "''' VISUALISING FAIRNESS METRICS: ACCURACY\n",
    "Input:  result (list containing lists with AOD, ACC, PREC and REC for respectively without and with reweighing),\n",
    "Output: Barplot of the accuracy\n",
    "'''\n",
    "def visualise_result(result):\n",
    "    N = len(result)\n",
    "    x = np.arange(1, N+1) \n",
    "    \n",
    "    x_labels = ()    \n",
    "    for i in x:\n",
    "        x_labels = x_labels[:] + (str(i),)\n",
    "    \n",
    "    bar_width = 0.4\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    br = ax.bar(x, result, bar_width)\n",
    "    ax.set_title('Accuracy')\n",
    "    ax.set_xlabel('# rounds')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ybound(0, 1)\n",
    "    \n",
    "    bar_label(ax, br)\n",
    "\n",
    "''' VISUALISE THE PERCENTAGES OF HIGH/LOW RISK LABELED MEN/WOMEN IN DATASET\n",
    "Input: amounts (percentages in list of\n",
    "        1. women with high risk label,\n",
    "        2. men with high risk label,\n",
    "        3. women with low risk label,\n",
    "        4. men with low risk label)\n",
    "Output: barplot of the amounts\n",
    "'''\n",
    "def visualise_amounts(amounts):\n",
    "    female_1 = amounts[0]\n",
    "    male_1 = amounts[1]\n",
    "    female_0 = amounts[2]\n",
    "    male_0 = amounts[3]\n",
    "    \n",
    "    N = len(female_1)\n",
    "    x = np.arange(1, N+1) \n",
    "    \n",
    "    x_labels = ()    \n",
    "    for i in x:\n",
    "        x_labels = x_labels[:] + (str(i),)\n",
    "    \n",
    "    bar_width = 0.2\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    br1 = ax.bar(x-1.5*bar_width, female_1, bar_width, color='darkorchid')\n",
    "    br2 = ax.bar(x-0.5*bar_width, female_0, bar_width, color='pink')\n",
    "    br3 = ax.bar(x+0.5*bar_width, male_1, bar_width, color='navy')\n",
    "    br4 = ax.bar(x+1.5*bar_width, male_0, bar_width, color='royalblue')\n",
    "    ax.set_title('Amounts')\n",
    "    ax.set_xlabel('# rounds')\n",
    "    ax.set_ylabel('Percentage of total amount of people')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    \n",
    "    bar_label(ax, br1, '.0f')\n",
    "    bar_label(ax, br2, '.0f')\n",
    "    bar_label(ax, br3, '.0f')\n",
    "    bar_label(ax, br4, '.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Conditional Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CALCULATE CONDITIONAL PROBABILITIES\n",
    "Based on the calculation posed in the thesis.\n",
    "'''\n",
    "# Calculate probability Arrested, given Gender and Risk score\n",
    "def cal_A_given_G_and_R(P_A, P_G, P_A_given_G, P_R_given_A):\n",
    "    P_G_and_R_given_A = cal_G_and_R_given_A(P_G, P_A_given_G, P_R_given_A, P_A)\n",
    "    P_G_and_R = cal_G_and_R(P_G_and_R_given_A, P_A, P_G, P_A_given_G, P_R_given_A)\n",
    "    \n",
    "    return (P_G_and_R_given_A * P_A) / P_G_and_R\n",
    "    \n",
    "## Calculate probability Gender and Risk, given Arrested\n",
    "def cal_G_and_R_given_A(P_G, P_A_given_G, P_R_given_A, P_A):\n",
    "    P_R_given_G_and_A = cal_R_given_G_and_A(P_G, P_A_given_G, P_R_given_A)\n",
    "    P_G_given_A = cal_G_given_A(P_A_given_G, P_G, P_A)\n",
    "    \n",
    "    return P_R_given_G_and_A * P_G_given_A \n",
    "\n",
    "### Calculate probability Risk, given Gender and Arrested\n",
    "def cal_R_given_G_and_A(P_G, P_A_given_G, P_R_given_A):\n",
    "    return P_G * P_A_given_G * P_R_given_A\n",
    "    \n",
    "### Calculate probability Gender, given Arrested\n",
    "def cal_G_given_A(P_A_given_G, P_G, P_A):\n",
    "    return (P_A_given_G * P_G) / P_A\n",
    "\n",
    "## Calculate joint probability Gender and Risk\n",
    "def cal_G_and_R(P_G_and_R_given_A, P_A, P_G, P_A_given_G, P_R_given_A):\n",
    "    P_A_c = 1 - P_A\n",
    "    P_A_c_given_G = 1 - P_A_given_G\n",
    "    \n",
    "    P_G_and_R_given_A_c = cal_G_and_R_given_A_c(P_G, P_A_c, P_A_c_given_G, P_R_given_A)\n",
    "    \n",
    "    return P_G_and_R_given_A * P_A + P_G_and_R_given_A_c * P_A_c  \n",
    "\n",
    "### Calculate Gender and Risk, given not Arrested\n",
    "def cal_G_and_R_given_A_c(P_G, P_A_c, P_A_c_given_G, P_R_given_A):\n",
    "    P_R_given_A_c = 1 - P_R_given_A\n",
    "    P_R_given_G_and_A_c = cal_R_given_G_and_A(P_G, P_A_c_given_G, P_R_given_A_c)\n",
    "    \n",
    "    P_G_given_A_c = cal_G_given_A(P_A_c_given_G, P_G, P_A_c)\n",
    "    \n",
    "    return P_R_given_G_and_A_c * P_G_given_A_c\n",
    "\n",
    "def get_fracs(P_A, P_M, P_F, P_A_given_M, P_A_given_F, P_1_given_A, P_0_given_A):\n",
    "    P_A_given_M_and_1 = cal_A_given_G_and_R(P_A, P_M, P_A_given_M, P_1_given_A)\n",
    "    P_A_given_M_and_0 = cal_A_given_G_and_R(P_A, P_M, P_A_given_M, P_0_given_A)\n",
    "    P_A_given_F_and_1 = cal_A_given_G_and_R(P_A, P_F, P_A_given_F, P_1_given_A)\n",
    "    P_A_given_F_and_0 = cal_A_given_G_and_R(P_A, P_F, P_A_given_F, P_0_given_A)\n",
    "    \n",
    "    return (P_A_given_M_and_0, P_A_given_M_and_1, P_A_given_F_and_0, P_A_given_F_and_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Scenario's\n",
    "\n",
    "By altering risk_male, risk_female and noise it is possible to retrieve the results of the thesis.\n",
    "\n",
    "## 2.1 General dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "noise = 'yes'\n",
    "n_people = 10000\n",
    "p_male = 0.6\n",
    "risk_male = 0.7 \n",
    "risk_female = 0.5\n",
    "\n",
    "# Creating dataset\n",
    "if noise == 'yes':\n",
    "    df, df_general = synthesize_data_with_noise(n_people, p_male, risk_male, risk_female)\n",
    "else:\n",
    "    df, df_general = synthesize_data(n_people, p_male, risk_male, risk_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Realities\n",
    "\n",
    "### 2.2.1 Survivorship bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentages to substract from reality (men low/high risk, women low/high risk) (0.6923076923076923, 0.8400000000000001, 0.5, 0.7)\n"
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "n_people_new = 500\n",
    "p_male_new = 0.5\n",
    "risk_male_new = 0.5 \n",
    "risk_female_new = 0.5\n",
    "\n",
    "P_A = 2/3\n",
    "P_M = 1/2\n",
    "P_F = 1/2\n",
    "P_A_given_M = 3/5\n",
    "P_A_given_F = 1/2\n",
    "P_1_given_A = 7/10\n",
    "P_0_given_A = 1/2\n",
    "\n",
    "fracs = get_fracs(P_A, P_M, P_F, P_A_given_M, P_A_given_F, P_1_given_A, P_0_given_A)\n",
    "print(\"Percentages to substract from reality (men low/high risk, women low/high risk)\", fracs)\n",
    "trn_val_tst_ratio = [0.5, 0.8]\n",
    "\n",
    "data_settings = (n_people_new, p_male_new, risk_male_new, risk_female_new, fracs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.1 Without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning without reweighing\n",
      "round 1\n",
      "round 2\n",
      "round 3\n",
      "round 4\n",
      "round 5\n",
      "round 6\n",
      "round 7\n",
      "round 8\n",
      "round 9\n",
      "round 10\n",
      "round 11\n",
      "round 12\n",
      "round 13\n",
      "round 14\n",
      "round 15\n",
      "round 16\n",
      "round 17\n",
      "round 18\n",
      "round 19\n",
      "round 20\n",
      "round 21\n",
      "round 22\n",
      "round 23\n",
      "round 24\n",
      "round 25\n",
      "round 26\n",
      "round 27\n",
      "round 28\n",
      "round 29\n",
      "round 30\n",
      "round 31\n",
      "round 32\n",
      "round 33\n",
      "round 34\n",
      "round 35\n",
      "round 36\n",
      "round 37\n",
      "round 38\n",
      "round 39\n",
      "round 40\n",
      "round 41\n",
      "round 42\n",
      "round 43\n",
      "round 44\n",
      "round 45\n",
      "round 46\n",
      "round 47\n",
      "round 48\n",
      "round 49\n",
      "round 50\n",
      "round 51\n",
      "round 52\n",
      "round 53\n",
      "round 54\n",
      "round 55\n",
      "round 56\n",
      "round 57\n",
      "round 58\n",
      "round 59\n",
      "round 60\n",
      "round 61\n",
      "round 62\n",
      "round 63\n",
      "round 64\n",
      "round 65\n",
      "round 66\n",
      "round 67\n",
      "round 68\n",
      "round 69\n",
      "round 70\n",
      "round 71\n",
      "round 72\n",
      "round 73\n",
      "round 74\n",
      "round 75\n",
      "round 76\n",
      "round 77\n",
      "round 78\n",
      "round 79\n",
      "round 80\n",
      "round 81\n",
      "round 82\n",
      "round 83\n",
      "round 84\n",
      "round 85\n",
      "round 86\n",
      "round 87\n",
      "round 88\n",
      "round 89\n",
      "round 90\n",
      "round 91\n",
      "round 92\n",
      "round 93\n",
      "round 94\n",
      "round 95\n",
      "round 96\n",
      "round 97\n",
      "round 98\n",
      "round 99\n",
      "round 100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ACC_mean_R1_Without, amounts_R1_without, results_mean, thresholds_mean = multiple_learning_mean(100, 5, df_general, trn_val_tst_ratio, data_settings, 'no', noise)\n",
    "visualise_result(ACC_mean_R1_Without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 776.  279.]\n",
      "  [ 401.  279.]\n",
      "  [ 376.    0.]\n",
      "  [1224. 1721.]\n",
      "  [ 389.  511.]\n",
      "  [ 834. 1210.]]\n",
      "\n",
      " [[ 810.  292.]\n",
      "  [ 413.  292.]\n",
      "  [ 397.    0.]\n",
      "  [1264. 1782.]\n",
      "  [ 406.  526.]\n",
      "  [ 858. 1255.]]\n",
      "\n",
      " [[ 846.  281.]\n",
      "  [ 431.  281.]\n",
      "  [ 415.    0.]\n",
      "  [1301. 1866.]\n",
      "  [ 420.  571.]\n",
      "  [ 881. 1296.]]\n",
      "\n",
      " [[ 883.  298.]\n",
      "  [ 446.  298.]\n",
      "  [ 438.    0.]\n",
      "  [1338. 1922.]\n",
      "  [ 438.  585.]\n",
      "  [ 900. 1338.]]\n",
      "\n",
      " [[ 922.  306.]\n",
      "  [ 464.  306.]\n",
      "  [ 458.    0.]\n",
      "  [1372. 1989.]\n",
      "  [ 452.  610.]\n",
      "  [ 921. 1379.]]]\n",
      "[0.469 0.468 0.463 0.455 0.467]\n"
     ]
    }
   ],
   "source": [
    "print(results_mean)\n",
    "print(thresholds_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.2 With debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning with reweighing\n",
      "round 1\n",
      "round 2\n",
      "round 3\n",
      "round 4\n",
      "round 5\n",
      "round 6\n",
      "round 7\n",
      "round 8\n",
      "round 9\n",
      "round 10\n",
      "round 11\n",
      "round 12\n",
      "round 13\n",
      "round 14\n",
      "round 15\n",
      "round 16\n",
      "round 17\n",
      "round 18\n",
      "round 19\n",
      "round 20\n",
      "round 21\n",
      "round 22\n",
      "round 23\n",
      "round 24\n",
      "round 25\n",
      "round 26\n",
      "round 27\n",
      "round 28\n",
      "round 29\n",
      "round 30\n",
      "round 31\n",
      "round 32\n",
      "round 33\n",
      "round 34\n",
      "round 35\n",
      "round 36\n",
      "round 37\n",
      "round 38\n",
      "round 39\n",
      "round 40\n",
      "round 41\n",
      "round 42\n",
      "round 43\n",
      "round 44\n",
      "round 45\n",
      "round 46\n",
      "round 47\n",
      "round 48\n",
      "round 49\n",
      "round 50\n",
      "round 51\n",
      "round 52\n",
      "round 53\n",
      "round 54\n",
      "round 55\n",
      "round 56\n",
      "round 57\n",
      "round 58\n",
      "round 59\n",
      "round 60\n",
      "round 61\n",
      "round 62\n",
      "round 63\n",
      "round 64\n",
      "round 65\n",
      "round 66\n",
      "round 67\n",
      "round 68\n",
      "round 69\n",
      "round 70\n",
      "round 71\n",
      "round 72\n",
      "round 73\n",
      "round 74\n",
      "round 75\n",
      "round 76\n",
      "round 77\n",
      "round 78\n",
      "round 79\n",
      "round 80\n",
      "round 81\n",
      "round 82\n",
      "round 83\n",
      "round 84\n",
      "round 85\n",
      "round 86\n",
      "round 87\n",
      "round 88\n",
      "round 89\n",
      "round 90\n",
      "round 91\n",
      "round 92\n",
      "round 93\n",
      "round 94\n",
      "round 95\n",
      "round 96\n",
      "round 97\n",
      "round 98\n",
      "round 99\n",
      "round 100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ACC_mean_R1_With, amounts_R1_with, results_mean, thresholds_mean = multiple_learning_mean(100, 5, df_general, trn_val_tst_ratio, data_settings, 'yes', noise)\n",
    "visualise_result(ACC_mean_R1_With)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 772.    0.]\n",
      "  [ 399.    0.]\n",
      "  [ 373.    0.]\n",
      "  [1228. 2000.]\n",
      "  [ 391.  790.]\n",
      "  [ 837. 1210.]]\n",
      "\n",
      " [[ 813.    0.]\n",
      "  [ 415.    0.]\n",
      "  [ 397.    0.]\n",
      "  [1265. 2077.]\n",
      "  [ 406.  821.]\n",
      "  [ 858. 1256.]]\n",
      "\n",
      " [[ 851.    0.]\n",
      "  [ 434.    0.]\n",
      "  [ 417.    0.]\n",
      "  [1303. 2154.]\n",
      "  [ 422.  856.]\n",
      "  [ 881. 1298.]]\n",
      "\n",
      " [[ 890.    0.]\n",
      "  [ 452.    0.]\n",
      "  [ 438.    0.]\n",
      "  [1341. 2231.]\n",
      "  [ 442.  894.]\n",
      "  [ 900. 1338.]]\n",
      "\n",
      " [[ 926.    0.]\n",
      "  [ 468.    0.]\n",
      "  [ 458.    0.]\n",
      "  [1382. 2308.]\n",
      "  [ 460.  928.]\n",
      "  [ 923. 1381.]]]\n",
      "[0.01 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(results_mean)\n",
    "print(thresholds_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Fair dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentages to substract from reality (men low/high risk, women low/high risk) (0.5, 0.7, 0.5, 0.7)\n"
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "n_people_new = 500\n",
    "p_male_new = 0.5\n",
    "risk_male_new = 0.7 \n",
    "risk_female_new = 0.5\n",
    "\n",
    "P_A = 2/3\n",
    "P_M = 1/2\n",
    "P_F = 1/2\n",
    "P_A_given_M = 1/2\n",
    "P_A_given_F = 1/2\n",
    "P_1_given_A = 7/10\n",
    "P_0_given_A = 1/2\n",
    "\n",
    "fracs = get_fracs(P_A, P_M, P_F, P_A_given_M, P_A_given_F, P_1_given_A, P_0_given_A)\n",
    "print(\"Percentages to substract from reality (men low/high risk, women low/high risk)\", fracs)\n",
    "trn_val_tst_ratio = [0.5, 0.8]\n",
    "\n",
    "data_settings = (n_people_new, p_male_new, risk_male_new, risk_female_new, fracs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.1 Without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning without reweighing\n",
      "round 1\n",
      "round 2\n",
      "round 3\n",
      "round 4\n",
      "round 5\n",
      "round 6\n",
      "round 7\n",
      "round 8\n",
      "round 9\n",
      "round 10\n",
      "round 11\n",
      "round 12\n",
      "round 13\n",
      "round 14\n",
      "round 15\n",
      "round 16\n",
      "round 17\n",
      "round 18\n",
      "round 19\n",
      "round 20\n",
      "round 21\n",
      "round 22\n",
      "round 23\n",
      "round 24\n",
      "round 25\n",
      "round 26\n",
      "round 27\n",
      "round 28\n",
      "round 29\n",
      "round 30\n",
      "round 31\n",
      "round 32\n",
      "round 33\n",
      "round 34\n",
      "round 35\n",
      "round 36\n",
      "round 37\n",
      "round 38\n",
      "round 39\n",
      "round 40\n",
      "round 41\n",
      "round 42\n",
      "round 43\n",
      "round 44\n",
      "round 45\n",
      "round 46\n",
      "round 47\n",
      "round 48\n",
      "round 49\n",
      "round 50\n",
      "round 51\n",
      "round 52\n",
      "round 53\n",
      "round 54\n",
      "round 55\n",
      "round 56\n",
      "round 57\n",
      "round 58\n",
      "round 59\n",
      "round 60\n",
      "round 61\n",
      "round 62\n",
      "round 63\n",
      "round 64\n",
      "round 65\n",
      "round 66\n",
      "round 67\n",
      "round 68\n",
      "round 69\n",
      "round 70\n",
      "round 71\n",
      "round 72\n",
      "round 73\n",
      "round 74\n",
      "round 75\n",
      "round 76\n",
      "round 77\n",
      "round 78\n",
      "round 79\n",
      "round 80\n",
      "round 81\n",
      "round 82\n",
      "round 83\n",
      "round 84\n",
      "round 85\n",
      "round 86\n",
      "round 87\n",
      "round 88\n",
      "round 89\n",
      "round 90\n",
      "round 91\n",
      "round 92\n",
      "round 93\n",
      "round 94\n",
      "round 95\n",
      "round 96\n",
      "round 97\n",
      "round 98\n",
      "round 99\n",
      "round 100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ACC_mean_R2_Without, _, results_mean, thresholds_mean = multiple_learning_mean(100, 5, df_general, trn_val_tst_ratio, data_settings, 'no', noise)\n",
    "visualise_result(ACC_mean_R2_Without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 775.  268.]\n",
      "  [ 399.  268.]\n",
      "  [ 375.    0.]\n",
      "  [1225. 1732.]\n",
      "  [ 392.  523.]\n",
      "  [ 834. 1209.]]\n",
      "\n",
      " [[ 801.  257.]\n",
      "  [ 416.  257.]\n",
      "  [ 385.    0.]\n",
      "  [1266. 1810.]\n",
      "  [ 405.  564.]\n",
      "  [ 861. 1246.]]\n",
      "\n",
      " [[ 826.  297.]\n",
      "  [ 430.  297.]\n",
      "  [ 397.    0.]\n",
      "  [1308. 1837.]\n",
      "  [ 421.  553.]\n",
      "  [ 887. 1284.]]\n",
      "\n",
      " [[ 853.  295.]\n",
      "  [ 446.  295.]\n",
      "  [ 407.    0.]\n",
      "  [1347. 1905.]\n",
      "  [ 436.  587.]\n",
      "  [ 912. 1319.]]\n",
      "\n",
      " [[ 883.  293.]\n",
      "  [ 465.  293.]\n",
      "  [ 419.    0.]\n",
      "  [1384. 1974.]\n",
      "  [ 453.  625.]\n",
      "  [ 931. 1350.]]]\n",
      "[0.448 0.461 0.449 0.48  0.447]\n"
     ]
    }
   ],
   "source": [
    "print(results_mean)\n",
    "print(thresholds_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.2 With debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning with reweighing\n",
      "round 1\n",
      "round 2\n",
      "round 3\n",
      "round 4\n",
      "round 5\n",
      "round 6\n",
      "round 7\n",
      "round 8\n",
      "round 9\n",
      "round 10\n",
      "round 11\n",
      "round 12\n",
      "round 13\n",
      "round 14\n",
      "round 15\n",
      "round 16\n",
      "round 17\n",
      "round 18\n",
      "round 19\n",
      "round 20\n",
      "round 21\n",
      "round 22\n",
      "round 23\n",
      "round 24\n",
      "round 25\n",
      "round 26\n",
      "round 27\n",
      "round 28\n",
      "round 29\n",
      "round 30\n",
      "round 31\n",
      "round 32\n",
      "round 33\n",
      "round 34\n",
      "round 35\n",
      "round 36\n",
      "round 37\n",
      "round 38\n",
      "round 39\n",
      "round 40\n",
      "round 41\n",
      "round 42\n",
      "round 43\n",
      "round 44\n",
      "round 45\n",
      "round 46\n",
      "round 47\n",
      "round 48\n",
      "round 49\n",
      "round 50\n",
      "round 51\n",
      "round 52\n",
      "round 53\n",
      "round 54\n",
      "round 55\n",
      "round 56\n",
      "round 57\n",
      "round 58\n",
      "round 59\n",
      "round 60\n",
      "round 61\n",
      "round 62\n",
      "round 63\n",
      "round 64\n",
      "round 65\n",
      "round 66\n",
      "round 67\n",
      "round 68\n",
      "round 69\n",
      "round 70\n",
      "round 71\n",
      "round 72\n",
      "round 73\n",
      "round 74\n",
      "round 75\n",
      "round 76\n",
      "round 77\n",
      "round 78\n",
      "round 79\n",
      "round 80\n",
      "round 81\n",
      "round 82\n",
      "round 83\n",
      "round 84\n",
      "round 85\n",
      "round 86\n",
      "round 87\n",
      "round 88\n",
      "round 89\n",
      "round 90\n",
      "round 91\n",
      "round 92\n",
      "round 93\n",
      "round 94\n",
      "round 95\n",
      "round 96\n",
      "round 97\n",
      "round 98\n",
      "round 99\n",
      "round 100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ACC_mean_R2_With, _, results_mean, thresholds_mean = multiple_learning_mean(100, 5, df_general, trn_val_tst_ratio, data_settings, 'yes', noise)\n",
    "visualise_result(ACC_mean_R2_With)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 776.    0.]\n",
      "  [ 398.    0.]\n",
      "  [ 377.    0.]\n",
      "  [1224. 2000.]\n",
      "  [ 391.  789.]\n",
      "  [ 833. 1211.]]\n",
      "\n",
      " [[ 802.    0.]\n",
      "  [ 418.    0.]\n",
      "  [ 384.    0.]\n",
      "  [1268. 2070.]\n",
      "  [ 405.  823.]\n",
      "  [ 863. 1247.]]\n",
      "\n",
      " [[ 828.    0.]\n",
      "  [ 433.    0.]\n",
      "  [ 396.    0.]\n",
      "  [1312. 2140.]\n",
      "  [ 424.  857.]\n",
      "  [ 887. 1283.]]\n",
      "\n",
      " [[ 857.    0.]\n",
      "  [ 452.    0.]\n",
      "  [ 405.    0.]\n",
      "  [1353. 2210.]\n",
      "  [ 443.  895.]\n",
      "  [ 910. 1315.]]\n",
      "\n",
      " [[ 889.    0.]\n",
      "  [ 472.    0.]\n",
      "  [ 417.    0.]\n",
      "  [1391. 2280.]\n",
      "  [ 458.  931.]\n",
      "  [ 933. 1349.]]]\n",
      "[0.01 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(results_mean)\n",
    "print(thresholds_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
